{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUmairAB/NewsGPT-Using-LangChain-and-FastAPI/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1Q7OHGaNPQ"
      },
      "source": [
        "# NewsGPT\n",
        "\n",
        "NewsGPT is a web-based application that utilizes the **LangChain** and **FastAPI** frameworks to generate concise summaries of news articles.\n",
        "\n",
        "## Instructions for Utilizing NewsGPT:\n",
        "\n",
        "To make use of this application, simply input the news article you wish to condense. The application will employ an advanced Large Language Model (LLM) to create a summary of the article.\n",
        "\n",
        "## Technical Specifications:\n",
        "\n",
        "The model leverages an open-source Large Language Model (LLM) available on the HuggingFace Hub. The current version of the notebook utilizes the [BART-Large-CNN](https://huggingface.co/facebook/bart-large-cnn) LLM developed by **Facebook**. However, if you prefer to use **OpenAI's ChatGPT** and possess the requisite API key, that option is also available. The notebook includes the necessary code and guidance for making this switch.\n",
        "\n",
        "The application retrieves the news article content from the provided link using LangChain. Subsequently, the LLM generates the summarized content, and the deployment is handled through FastAPI, which is built upon the REST framework.\n",
        "\n",
        "\n",
        "To obtain the LLM from HuggingFace, it's essential to safeguard your **Access Key**. To ensure its security when sharing the notebook on your GitHub repository, a prudent approach is taken. The key is first stored within a Python file, which is subsequently uploaded to the current Colab session. Following this, the file is relocated to a concealed folder, and access permissions are modified to restrict it to the current session exclusively. If you are replicating this code and you won't be sharing your code publicly, you may opt to omit this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taclOeMT_H9o",
        "outputId": "4b4c76a4-b413-470b-da2e-15a02a673ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#Upgrade pip\n",
        "!pip install -q --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAVQu2NC70J7",
        "outputId": "6c3adb4a-a45c-46fe-f7ed-de2e6481c8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m910.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=d939874822522b61cc6fcd7b7f4e8580ece6196802990feb88f73c10b83b1035\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Install the required packages.\n",
        "# Use the -q tag for downloading the files quietly.\n",
        "\n",
        "#Install LangChain\n",
        "!pip install -q langchain\n",
        "\n",
        "#Install uvicorn\n",
        "!pip install -q uvicorn\n",
        "\n",
        "#Install FastAPI\n",
        "!pip install -q fastapi\n",
        "\n",
        "#Install pyngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "#Install HuggingFace\n",
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "kLUsYyoeMpZy",
        "outputId": "a5d9983d-4c02-49ee-dbaf-238f98d2ff21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import files\\nfiles.upload()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Create the files_upload session to upload the file secret_key.py\n",
        "# in which the HuggingFace API key is stored\n",
        "\"\"\"\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\"\"\"\n",
        "\n",
        "#I have commented the above code because I am manually uploading the secret_key.py file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9alGZCaK07Yx"
      },
      "outputs": [],
      "source": [
        "#Create \"key_directory\" directory\n",
        "!mkdir ~/.key_directory\n",
        "\n",
        "#Move the secret_key.py file to this directory\n",
        "!mv secret_key.py ~/.key_directory/\n",
        "\n",
        "#Change the file access rights to the current user only\n",
        "!chmod 600 ~/.key_directory/secret_key.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsfJsSnV9z2R",
        "outputId": "718db653-ae78-4189-d134-f13691326f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.key_directory\n"
          ]
        }
      ],
      "source": [
        "#Change the current directory to the hidden directory\n",
        "%cd ~/.key_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZKcUysgJ96Yu"
      },
      "outputs": [],
      "source": [
        "#Extract the API key as API_key\n",
        "from secret_key import API_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyj4Cl14A25A",
        "outputId": "202f7d1d-68ba-4ff0-cad3-48f5057e54d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ],
      "source": [
        "#cd out of the current hidden directory to the parent directory\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iLTLZ0fqz-N9"
      },
      "outputs": [],
      "source": [
        "#Create an Environment Variable named HUGGINGFACEHUB_API_TOKEN to store the API_key\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = API_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wxj5_WtJqo6M"
      },
      "outputs": [],
      "source": [
        "#Load necessary libraries\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "#Declare the HuggingFace repo id\n",
        "repo_id = \"facebook/bart-large-cnn\"\n",
        "\n",
        "#Instantiate the LLM\n",
        "llm = HuggingFaceHub(repo_id=repo_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5B71IwK0pep"
      },
      "source": [
        "I am currently using the [BART-Large-CNN](https://huggingface.co/facebook/bart-large-cnn) by **Facebook**. But if you want to use the OpenAI's ChatGPT and has the API key, then store the API key as Environment variable. Then un-comment the following cell code to instantiate the OpenAI's ChatGPT as your desired LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        },
        "id": "bDPnOoHgqpD1",
        "outputId": "601be5ac-7c29-4469-d0d4-083722f5f280"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom langchain.chat_models import ChatOpenAI\\nllm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#If you want to use the OpenAI and has the API key, you can un-comment the following code\n",
        "\"\"\"\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-1UQKUc3npb"
      },
      "source": [
        "## Define FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1-v9KBCsm7i5"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import HTMLResponse\n",
        "\n",
        "\n",
        "#Instantiate the app\n",
        "app = FastAPI()\n",
        "\n",
        "#The following code is necessary to run the FastAPI app in Colab\n",
        "# But if you are running it locally, then you can un-comment the following\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "#Define the root function/landing page\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Welcome to NewsGPT Website\"}\n",
        "\n",
        "#Define the summary page\n",
        "@app.get(\"/summary\")\n",
        "async def summarizer(URL:str):\n",
        "    #Load the necessary libraries\n",
        "    from langchain.document_loaders import WebBaseLoader\n",
        "    from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "    #Scrape the URL\n",
        "    loader = WebBaseLoader(URL)\n",
        "    docs = loader.load()\n",
        "\n",
        "    #Instantiate the Chain Object\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "    #Use the chain on the scraped website\n",
        "    result = chain.run(docs)\n",
        "\n",
        "    return {\"Summary of the news article\":result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RTPY-Rjm7_V",
        "outputId": "f0ec68fb-bdae-4d5e-9628-b051751f36d6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-09-10T08:25:24+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n",
            "INFO:     Started server process [336]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://ea78-35-194-207-7.ngrok.io\n",
            "INFO:     39.59.22.204:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     39.59.22.204:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.theguardian.com/commentisfree/2023/aug/11/ai-tech-designers-tool-communities HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.dawn.com/news/1775013/climate-activists-block-dutch-motorway-in-major-protest HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.dawn.com/news/1774979/musks-x-sues-over-having-to-post-moderation-policies HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.theguardian.com/technology/2023/sep/10/china-troubles-could-upset-apples-cart-as-it-prepares-to-launch-the-iphone-15 HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.theguardian.com/world/2023/sep/10/chinas-good-for-marriage-womens-trend-ignites-social-media-debate HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.theguardian.com/world/2023/sep/10/chinas-good-for-marriage-womens-trend-ignites-social-media-debate HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https://www.theguardian.com/world/2023/sep/10/chinas-good-for-marriage-womens-trend-ignites-social-media-debate HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https%3A%2F%2Fwww.theguardian.com%2Fworld%2F2023%2Fsep%2F10%2Fchinas-good-for-marriage-womens-trend-ignites-social-media-debate HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /summary?URL=https%3A%2F%2Fwww.theguardian.com%2Fworld%2F2023%2Fsep%2F10%2Fchinas-good-for-marriage-womens-trend-ignites-social-media-debate HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     39.59.22.204:0 - \"GET /doc HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [336]\n"
          ]
        }
      ],
      "source": [
        "#Run the FastAPI app on local server\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The App is accessible using the **Public URL** as long as the cell is running. We can use this end-point to access the app through Python code in local IDE or in any Command Line Interface (CLI) terminal like GitBash."
      ],
      "metadata": {
        "id": "hnYN-7kyTO-R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd8vZWHJfWLSCNnQZhkeez",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}